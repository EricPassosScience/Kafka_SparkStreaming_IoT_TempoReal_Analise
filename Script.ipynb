{"cells":[{"cell_type":"code","source":["# Importa o findspark e inicializa\n# import findspark\n# findspark.init()\n\n# Import required modules\nimport pyspark\nfrom pyspark.streaming import StreamingContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, DoubleType\nfrom pyspark.sql.functions import col, from_json"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7b3c58a1-c53c-45f9-b329-29d82d376d20","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Precisamos incluir o conector de integração do Spark Streaming com Apache Kafka. Documentação ->: https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da9567b3-0e6b-4776-8f24-16bd00e31415","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Conector\nimport os \nos.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 pysparkshell'\n\n# Cria a Sessão Sparl\nspark = SparkSession.builder.appName(\"IoT-Sensores\").getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a83506ea-e46b-43d7-bd67-659758edfba4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Leitura do Kafka Spark Structured Stream\n# Vamos criar uma subscrição (assinatura) no tópico que tem o streaming de dados que desejamos \"puxar\" os dados. \ndf = spark \\\n  .readStream \\\n  .format(\"kafka\") \\\n  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n  .option(\"subscribe\", \"Eric\") \\\n  .load()\n\n# Definição do Schema da Fonte de Dados\n# Definimos o schema dos dados que desejamos capturar para análise (temperatura)\nesquema_dados_temp = StructType([StructField(\"leitura\",\n                                            StructType([StructField(\"temperatura\", DoubleType(), True)]), True)])\n\n# Definimos o schema global dos dados no streaming\nesquema_dados = StructType([\n  StructField(\"id_sensor\", StringType(), True),\n  StructField(\"id_equipamento\", StringType(), True),\n  StructField(\"sensor\", StringType(), True),\n  StructField(\"data_evento\", StringType(), True),\n  StructField(\"padrao\", esquema_dados_temp)\n])\n\n# Parse de Fonte de Dados\n# Converte do formato JSON, para um formato tabular com o schema requerido\n\n# Capturamos cada linha de dado (cada valor) como string\ndf_conversao = df.selectExpr(\"CAST(value AS  STRING)\")\n\n# Parse do formato JSON em dataframe\ndf_conversao = df_conversao.withColumn(\"jsonData\", from_json(col(\"value\"), esquema_dados)).select(\"jsonData.*\")\n\ndf_conversao.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a36b2f5-bb43-4521-a0da-1c83dac5cea4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Preparando o Dataframe para o formato ideal para análise\n\n# Renomenando as colunas para simplificar nossa análise\ndf_conversao_temp_sensor = df_conversao.select(col(\"padrao.leitura.temperatura\").alias(\"temperatura\"),\n                                              col(\"sensor\"))\n\ndf_conversao_temp_sensor.printSchema()\n\n# Não podemos visualizar o dataframe, pois a fonte é de streaming\ndf_conversao_temp_sensor.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"47e946da-b9e0-435b-9922-9ba894bd119e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Análise de Dados em Tempo Real\n# Aqui temos o objeto que irá conter nossa análise, o cálculo da média das temperaturas por sensor\ndf_media_temp_sensor = df_conversao_temp_sensor.groupby(\"sensor\").mean(\"temperatura\")\n\n# df_media_temp_sensor.printSchema()\n\n# Renomeamos as colunas para simplificar nossa análise\ndf_media_temp_sensor = df_media_temp_sensor.select(col(\"sensor\").alias(\"sensor\"),\n                                                 col(\"avg(temperatura)\").alias(\"media_temp\"))\n\ndf_media_temp_sensor.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eb30afc2-c7a6-442b-b48a-8ba8f15cd6e5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Abaixo abrimos o streaming para análise de dados em tempo real, imprimindo o resultado no console\n\n# Objeto que inicia a consulta ao streaming com formato de console\nquery = df_media_temp_sensor.writeStream.outputMode(\"complete\").format(\"console\").start()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a6b26817-7ebb-4c95-85cb-d7b972ba5dd5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["O código anterior está rodando em segundo plano. Se o deixarmos inativo por muito tempo, derrubaremos o streaming. uma alternativa. é executar a query do seguinte modo: \"query.awaitTermination()\". É o que fizemos na cálula a seguir."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29bdb229-7b88-4b8f-a582-915568fde875","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Executa a query do streaming e evitamos que o processo seja encerrado\n# Agora não executará em segundo plano. \nquery.awaitTermination()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"356074bb-7812-4919-a08f-13ca8fe23adc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["O problema do método anterior, é que ele somente encerra, quando clicarmos em stop. Mas veremos uma altertiva, para que consigamo parar e executar no momento que quisermos."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09ae5d12-50c7-4b08-88f5-51713086ea4f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Status da query\nquery.status\n\n# Resumo de tudo que foi feito na ultima execução\nquery.lastProgress\n\n# Explica a query\n# Plano de execução da query\nquery.explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4af9ba37-301b-4d3d-912c-75cfbaa28618","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# SQL na Análise de Dados em Tempo Real\n# Objeto que inicia a consulta ao streaming com formato de memória (cria tabela temporária)\nquery_memoria = df_media_temp_sensor \\\n  .writeStream \\\n  .queryName(\"Eric\") \\\n  .outputMode(\"complete\") \\\n  .format(\"memory\") \\\n  .start()\n\n# Streams ativados (quantos streams estão ativados)\nspark.streams.active"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c2017d94-fbf5-4cbc-b1b9-f39c6ef2d3fe","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Vamos manter a query executando por algum tempo e aplicando SQL aos dados em tempo real\nfrom time import sleep\n\nfor x in range(10):\n  \n  # select do sensor, arredonda a média para duas casas decimais, somente na onde a média de temperatura for maior que 65\n  spark.sql(\"select sensor, round(media_temp, 2) as media from Eric where media_temp > 65\").show\n  sleep(3)\n\nquery_memoria.stop()\n# FIM! "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2971fbe8-808b-4274-b65a-a10ea13c42cf","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Script","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3701379402059117}},"nbformat":4,"nbformat_minor":0}
